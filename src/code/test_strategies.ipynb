{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9ae32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangyijie/miniconda3/envs/sam_env/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import functools\n",
    "from torchvision import transforms\n",
    "from utils.utils import get_strategy\n",
    "from dataloaders.dataset_fetalhead import BaseDataSets_HC18\n",
    "import albumentations as A\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "from networks.vision_transformer import SwinUnet as ViM_seg\n",
    "from networks.swin_transformer_unet_skip_expand_decoder_sys import SwinTransformerSys\n",
    "from config import get_config\n",
    "from networks.unet import UNet as Unet2D\n",
    "from networks.archs import UNext\n",
    "from utils.losses import softmax_dice_loss, info_nce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc15092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConstraLoss_AvgProj(inputs, targets, ndf=64):\n",
    "    m=nn.AdaptiveAvgPool2d(ndf)\n",
    "    input_pro = m(inputs)\n",
    "    input_pro = input_pro.view(inputs.size(0),inputs.size(1),-1) #N*C\n",
    "    targets_pro = m(targets)\n",
    "    targets_pro = targets_pro.view(targets.size(0),targets.size(1),-1)#N*C\n",
    "    input_normal = nn.functional.normalize(input_pro,p=2,dim=1)\n",
    "    targets_normal = nn.functional.normalize(targets_pro,p=2,dim=1)\n",
    "    res = (input_normal - targets_normal)\n",
    "    print(res.shape)\n",
    "    res = res * res\n",
    "    print(res.shape)\n",
    "    loss = torch.mean(res)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082f8679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 4096])\n",
      "torch.Size([4, 2, 4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0034)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.rand(4,2,448,448)\n",
    "x2 = torch.rand(4,2,448,448)\n",
    "ConstraLoss_AvgProj(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4629dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNext(in_chns=3, out_channels=2, img_size=448, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912c3226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNext(\n",
       "  (encoder1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (encoder2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (encoder3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (ebn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ebn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ebn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm3): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dnorm3): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  (dnorm4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (block1): ModuleList(\n",
       "    (0): shiftedBlock(\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): shiftmlp(\n",
       "        (fc1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (dwconv): DWConv(\n",
       "          (dwconv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block2): ModuleList(\n",
       "    (0): shiftedBlock(\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): shiftmlp(\n",
       "        (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dwconv): DWConv(\n",
       "          (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dblock1): ModuleList(\n",
       "    (0): shiftedBlock(\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): shiftmlp(\n",
       "        (fc1): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (dwconv): DWConv(\n",
       "          (dwconv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=160, out_features=160, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dblock2): ModuleList(\n",
       "    (0): shiftedBlock(\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): shiftmlp(\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (dwconv): DWConv(\n",
       "          (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (patch_embed3): OverlapPatchEmbed(\n",
       "    (proj): Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (patch_embed4): OverlapPatchEmbed(\n",
       "    (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder1): Conv2d(256, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (decoder2): Conv2d(160, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (decoder3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (decoder4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (decoder5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dbn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dbn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dbn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dbn4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (soft): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(1,3,448,448)\n",
    "testout, emb_out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c22fb318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, j: 0, j+args.labeled_bs: 1\n",
      "i: 0, j: 1, j+args.labeled_bs: 2\n",
      "i: 0, j: 2, j+args.labeled_bs: 3\n",
      "i: 0, j: 3, j+args.labeled_bs: 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    for j in range(5-1):\n",
    "        print(f'i: {i}, j: {j}, j+args.labeled_bs: {j+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f6ac49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats1 = torch.randn(5, 50176)\n",
    "feats2 = torch.randn(5, 50176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8ce947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00, -2.2207e-03,  3.6291e-03,  9.1015e-03, -1.0551e-03],\n",
      "        [-2.2207e-03,  1.0000e+00, -3.5107e-03,  4.9809e-04, -5.8683e-04],\n",
      "        [ 3.6291e-03, -3.5107e-03,  1.0000e+00, -9.2778e-03,  2.5771e-03],\n",
      "        [ 9.1015e-03,  4.9809e-04, -9.2778e-03,  1.0000e+00,  5.3993e-04],\n",
      "        [-1.0551e-03, -5.8683e-04,  2.5771e-03,  5.3993e-04,  1.0000e+00]])\n",
      "torch.Size([5, 5])\n",
      "1\n",
      "tensor([[False, False, False, False,  True],\n",
      "        [ True, False, False, False, False],\n",
      "        [False,  True, False, False, False],\n",
      "        [False, False,  True, False, False],\n",
      "        [False, False, False,  True, False]])\n",
      "tensor(1.4321)\n"
     ]
    }
   ],
   "source": [
    "cos_sim = F.cosine_similarity(feats1[:,None,:], feats1[None,:,:], dim=-1)\n",
    "print(cos_sim)\n",
    "# Mask out cosine similarity to itself\n",
    "self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "print(self_mask.shape)\n",
    "cos_sim.masked_fill_(self_mask, -9e15)\n",
    "# Find positive example -> batch_size//2 away from the original example\n",
    "pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2-1, dims=0)\n",
    "# pos_mask = self_mask.roll(shifts=cos_sim.shape[0], dims=0)\n",
    "print(cos_sim.shape[0]//2-1)\n",
    "print(pos_mask)\n",
    "# InfoNCE loss\n",
    "cos_sim = cos_sim / 0.07\n",
    "nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "nll = nll.mean()\n",
    "print(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e94e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss_2(feats1,feats2):\n",
    "    # Calculate cosine similarity\n",
    "    # feats1_norm = F.normalize(feats1, dim=1)\n",
    "    # feats2_norm = F.normalize(feats2, dim=1)\n",
    "    # cos_sim = torch.matmul(feats1_norm, feats2_norm.T)\n",
    "\n",
    "    cos_sim = F.cosine_similarity(feats1[:,None,:], feats2[None,:,:], dim=-1)\n",
    "    cos_sim = cos_sim / 0.07\n",
    "    pos = torch.diag(cos_sim, 0)\n",
    "    # print(f'{feats1.shape}, and {feats2.shape}')\n",
    "    # print(f'cos_sim {cos_sim.shape}')\n",
    "    # Mask out cosine similarity to itself\n",
    "    self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "    print(f'self_mask {self_mask.shape}')\n",
    "    cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    # Find positive example -> batch_size//2 away from the original example\n",
    "    # pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
    "    # InfoNCE loss\n",
    "    # nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "    nll = -pos + torch.logsumexp(cos_sim, dim=-1)\n",
    "    nll = nll.mean()\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b0cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class projectors(nn.Module):\n",
    "    def __init__(self, input_nc=768, ndf=256, norm_layer=nn.BatchNorm2d):\n",
    "        super(projectors, self).__init__()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv_1 = nn.Linear(input_nc, ndf)\n",
    "        # self.conv_2 = nn.Linear(ndf, ndf*2)\n",
    "    def forward(self, input):\n",
    "        x_out = self.conv_1(input)\n",
    "        # x_out = self.pool(x_out)\n",
    "        # x_out = self.conv_2(x_0)\n",
    "        # x_out = self.pool(x_out)\n",
    "        return x_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e1b75f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "input_x = torch.randn(5, 64, 768)\n",
    "input_y = torch.randn(5, 256, 8, 8)\n",
    "# emb_x = torch.flatten(input_x, start_dim=1)\n",
    "# emb_y = torch.flatten(input_y, start_dim=1)\n",
    "emb_x = input_x\n",
    "emb_y = input_y.view(5, 256, -1).permute(0, 2, 1)\n",
    "print(emb_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b8bbabce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 256])\n",
      "torch.Size([5, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "proj_1 = projectors(input_nc=768, ndf=256)\n",
    "# proj_2 = projectors(input_nc=16, ndf=64)\n",
    "proj_x = proj_1(emb_x)\n",
    "# proj_y = proj_2(emb_y)\n",
    "print(proj_x.shape)\n",
    "print(emb_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce74f8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(5, 64)\n",
    "b = torch.randn(5, 64)\n",
    "c = torch.cat([a, b], dim=0)\n",
    "d = torch.cat([b, a], dim=0)\n",
    "print(c.shape)\n",
    "test = F.cosine_similarity(c, d, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6c933f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1630,  0.0817,  0.1735, -0.1563,  0.0131],\n",
       "        [ 0.0332,  0.1688, -0.1064, -0.1731,  0.0920],\n",
       "        [ 0.0724,  0.0579,  0.0768,  0.0692,  0.1843],\n",
       "        [ 0.0178, -0.0041,  0.3110, -0.0190, -0.0813],\n",
       "        [-0.1418,  0.0030, -0.2234,  0.0946, -0.0430]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_ab = F.cosine_similarity(a[:,None,:], b[None,:,:], dim=-1)\n",
    "cos_sim_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378b813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6597)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_nce_1 = info_nce_loss(a, b)\n",
    "info_nce_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d6bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_mask torch.Size([5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9896)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_nce_2 = info_nce_loss_2(a, b)\n",
    "info_nce_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2e6286f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3287,  1.1678,  2.4785, -2.2325,  0.1865],\n",
       "        [ 0.4742,  2.4121, -1.5204, -2.4724,  1.3137],\n",
       "        [ 1.0346,  0.8274,  1.0968,  0.9891,  2.6327],\n",
       "        [ 0.2544, -0.0590,  4.4435, -0.2712, -1.1612],\n",
       "        [-2.0257,  0.0431, -3.1919,  1.3515, -0.6142]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_norm = F.normalize(a, dim=1)            # Shape: (5, 64)\n",
    "b_norm = F.normalize(b, dim=1)       # Shape: (64,)\n",
    "\n",
    "cos_sim = torch.matmul(a_norm, b_norm.T)\n",
    "cos_sim = cos_sim / 0.07\n",
    "pos = torch.diagonal(cos_sim.clone(), 0)\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "68538e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0000e+15,  1.1678e+00,  2.4785e+00, -2.2325e+00,  1.8655e-01],\n",
       "        [ 4.7425e-01, -9.0000e+15, -1.5204e+00, -2.4724e+00,  1.3137e+00],\n",
       "        [ 1.0346e+00,  8.2736e-01, -9.0000e+15,  9.8906e-01,  2.6327e+00],\n",
       "        [ 2.5441e-01, -5.9048e-02,  4.4435e+00, -9.0000e+15, -1.1612e+00],\n",
       "        [-2.0257e+00,  4.3135e-02, -3.1919e+00,  1.3515e+00, -9.0000e+15]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "cos_sim.masked_fill_(self_mask, -9e15)\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4dc73a",
   "metadata": {},
   "source": [
    "### Test SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "564fa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.prompt import get_bounding_box\n",
    "from transformers import SamProcessor\n",
    "from transformers import SamModel\n",
    "from utils.losses import softmax_kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47d6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cabda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50826a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load SAM model from /mnt/storage/fangyijie/ft_sam/checkpoints_head/onlyreal/checkpoint_FTSAM_epoch_19_BS_1_TRAINSIZE_25_Real_20250417-230749\n"
     ]
    }
   ],
   "source": [
    "sam_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "pretr_sam_model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n",
    "sam_checkpoint = '/mnt/storage/fangyijie/ft_sam/checkpoints_head/onlyreal/checkpoint_FTSAM_epoch_19_BS_1_TRAINSIZE_25_Real_20250417-230749'\n",
    "if sam_checkpoint:\n",
    "    model_state = torch.load(sam_checkpoint, map_location=torch.device(\"cuda:1\"))\n",
    "    pretr_sam_model.load_state_dict(model_state)\n",
    "    pretr_sam_model.to(device)\n",
    "    print(f\"Load SAM model from {sam_checkpoint}\")\n",
    "\n",
    "# make sure to freeze SAM\n",
    "for name, param in pretr_sam_model.named_parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc121bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 448, 448])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_in = torch.randn(5, 3, 448, 448).to(device)\n",
    "test = torch.argmax(a_in, dim=0, keepdim=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f61ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(image=None, nobox=True):\n",
    "\n",
    "    if nobox:\n",
    "        # bbox = [0, 0, image.size[0], image.size[1]]\n",
    "        bbox = [np.random.randint(0, 20),\n",
    "                np.random.randint(0, 20),\n",
    "                image.shape[0] - np.random.randint(0, 20),\n",
    "                image.shape[1] - np.random.randint(0, 20)]\n",
    "\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67bb3fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448, 448, 3])\n",
      "448\n",
      "torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "pretr_sam_model.eval()\n",
    "for idx in range(1):\n",
    "    image = a_in[idx].unsqueeze(0)\n",
    "    image = torch.argmax(image, dim=0)\n",
    "    image = image.permute(1, 2, 0)\n",
    "    print(image.shape)\n",
    "    print(image.shape[0])\n",
    "    input_boxes = get_bounding_box(image, nobox = True)\n",
    "    inputs = sam_processor(image.cpu().numpy(), input_boxes=[[input_boxes]], return_tensors=\"pt\", do_rescale=False).to(torch.float32).to(device)\n",
    "    # forward pass\n",
    "    # note that the authors use `multimask_output=False` when performing inference\n",
    "    output_logits = pretr_sam_model(**inputs, multimask_output=False).pred_masks.squeeze(0)\n",
    "    print(output_logits.shape)\n",
    "    outputs.append(output_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a9ddbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_input = a_in[1, 0, :, :]\n",
    "a_input = a_input[None,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "569fd220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 448, 448])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_outputs = F.interpolate(outputs.unsqueeze(1), size=(448, 448), mode='bilinear', align_corners=False)\n",
    "upsampled_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5806a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_losses = []\n",
    "for i in range(5):\n",
    "    kl_div = softmax_kl_loss(a_input, upsampled_outputs.squeeze(1), sigmoid=True)\n",
    "    # kl_div\n",
    "    kl_losses.append(kl_div.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f1cb8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6986963748931885"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(kl_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e894a27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply sigmoid\n",
    "medsam_seg_prob = torch.sigmoid(outputs)\n",
    "medsam_seg_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "202195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_log_softmax = torch.log(torch.sigmoid(outputs))\n",
    "target_softmax = torch.sigmoid(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7518e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1014, device='cuda:1')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_div = F.kl_div(input_log_softmax, target_softmax, reduction='mean')\n",
    "kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "326f1590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 448, 448])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 448, 448)\n",
    "test = []\n",
    "for i in range(5):\n",
    "    test.append(x)\n",
    "\n",
    "torch.stack(test).size()\n",
    "# torch.stack((x, y), dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e928b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1037)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = torch.randn(5, 448, 448)\n",
    "a2 = torch.randn(5, 448, 448)\n",
    "kl_div = softmax_kl_loss(a1, a2, sigmoid=True)\n",
    "kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a17133e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 448])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Upsample(scale_factor=1.75, mode='nearest')\n",
    "outputs_448 = m(outputs)\n",
    "outputs_448.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6264e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4b8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60dcea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8ffb09b",
   "metadata": {},
   "source": [
    "### Test Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78adad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformerSys expand initial----depths:[2, 2, 2, 2];depths_decoder:[1, 2, 2, 2];drop_path_rate:0.2;num_classes:2\n",
      "---final upsample expand_first---\n"
     ]
    }
   ],
   "source": [
    "swin_unet = SwinTransformerSys(img_size=448,\n",
    "                patch_size=4,\n",
    "                in_chans=3,\n",
    "                num_classes=2,\n",
    "                embed_dim=96,\n",
    "                depths=[ 2, 2, 2, 2 ],\n",
    "                num_heads=[ 3, 6, 12, 24 ],\n",
    "                window_size=7,\n",
    "                mlp_ratio=4.0,\n",
    "                qkv_bias=True,\n",
    "                qk_scale=False,\n",
    "                drop_rate=0.0,\n",
    "                drop_path_rate=0.2,\n",
    "                ape=False,\n",
    "                patch_norm=True,\n",
    "                use_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc51a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = torch.randn(1, 3, 448, 448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e05319a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "_, emb = swin_unet.forward_features(input_x)\n",
    "bottleneck = emb[-1]\n",
    "print(bottleneck.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3d83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Unet2D(in_chns=3, class_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01662b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "y_unet = model1(input_x)\n",
    "print(y_unet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b22bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNext_model = UNext(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    img_size=256,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85082a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256])\n",
      "torch.Size([1, 256, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "y_UNext, emb = UNext_model(input_x)\n",
    "print(y_UNext.shape)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb66845",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ae4c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2 = nn.Linear(768, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb747c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Network(nn.Module):\n",
    "    def __init__(self,in_dim,hid):\n",
    "        super(NN_Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_dim,hid)\n",
    "\n",
    "    def forward(self, input_array):\n",
    "        h = self.linear1(input_array)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4e97fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196864"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_net = NN_Network(768, 256)\n",
    "total_params = sum(p.numel() for p in nn_net.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94df669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "test = fc2(bottleneck)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330a453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d2ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/mnt/storage/fangyijie/HC18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404ab347",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_transforms = A.Compose(\n",
    "    [\n",
    "        A.Rotate(limit=20, p=1.0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2),contrast_limit=(-0.5, 0.5)),\n",
    "        A.Blur(blur_limit=(3, 3), p=0.3),\n",
    "        A.GaussNoise(std_range=(0.05, 0.1), p=0.3),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.VerticalFlip(p=0.9),\n",
    "        # A.Normalize(\n",
    "        #     mean=[0.0, 0.0, 0.0],\n",
    "        #     std=[1.0, 1.0, 1.0],\n",
    "        #     max_pixel_value=255.0,\n",
    "        # ),\n",
    "        ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1a5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((448, 448), transforms.InterpolationMode.NEAREST),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb582ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train_unlabled = BaseDataSets_HC18(base_dir=root_path, split=\"train\", \n",
    "                                      islabeled=False, \n",
    "                                      transform=None, default_transform=tensor_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d292cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transforms\n",
    "db_train_unlabled.transform = tr_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097774d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/storage/fangyijie/HC18/ssl/train/labeled_data/None/data_al_2_None.list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m db_train_unlabled \u001b[38;5;241m=\u001b[39m BaseDataSets_HC18(base_dir\u001b[38;5;241m=\u001b[39mroot_path, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                       islabeled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      3\u001b[0m                                       isAL\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                                       transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, default_transform\u001b[38;5;241m=\u001b[39mtensor_transforms)\n",
      "File \u001b[0;32m~/ssl_us/SSL_Cervical_Segmentation/src/code/dataloaders/dataset_fetalhead.py:65\u001b[0m, in \u001b[0;36mBaseDataSets_HC18.__init__\u001b[0;34m(self, base_dir, split, num, transform, default_transform, label_transform, islabeled, isAL, alNum, stgrategy)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ssl/train/unlabeled_data/data.list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f1:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munlabeled_list \u001b[38;5;241m=\u001b[39m f1\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ssl/train/labeled_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstgrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data_al_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malNum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f1:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabeled_list \u001b[38;5;241m=\u001b[39m f1\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munlabeled_list, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabeled_list)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/storage/fangyijie/HC18/ssl/train/labeled_data/None/data_al_2_None.list'"
     ]
    }
   ],
   "source": [
    "db_train_unlabled = BaseDataSets_HC18(base_dir=root_path, split=\"train\", \n",
    "                                      islabeled=False, \n",
    "                                      isAL=True,\n",
    "                                      transform=None, default_transform=tensor_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaab0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_data in db_train_unlabled:\n",
    "    mask = i_data['label']\n",
    "    print(i_data['idx'])\n",
    "    print(i_data['name'])\n",
    "    print(mask.shape)\n",
    "    print(torch.argmax(mask))\n",
    "    print(torch.argmin(mask))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = get_strategy(\"RandomSampling\")(db_train_unlabled) # load strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da44a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_idxs = strategy.query(5) #([500, 1, 128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50353fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb96a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff9e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_slice = 5\n",
    "al_iter = 2\n",
    "strategy_name = \"RandomSampling\"\n",
    "# strategy_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train_labled = BaseDataSets_HC18(base_dir=root_path, split=\"train\", num=labeled_slice, islabeled=True, \n",
    "                                        transform=None, default_transform=tensor_transforms)\n",
    "db_train_labled_da = BaseDataSets_HC18(base_dir=root_path, split=\"train\", num=labeled_slice, islabeled=True, \n",
    "                                        transform=tr_transforms, default_transform=tensor_transforms)\n",
    "\n",
    "db_train = ConcatDataset([db_train_labled, db_train_labled_da])\n",
    "\n",
    "if strategy_name is not None and al_iter > 1:\n",
    "    db_train_al_labled = BaseDataSets_HC18(base_dir=root_path, split=\"train\", num=labeled_slice, islabeled=True, \n",
    "                                            isAL=True, alNum=al_iter, stgrategy=strategy_name,\n",
    "                                            transform=None, default_transform=tensor_transforms)\n",
    "    db_train_al_labled_da = BaseDataSets_HC18(base_dir=root_path, split=\"train\", num=labeled_slice, islabeled=True, \n",
    "                                                isAL=True, alNum=al_iter, stgrategy=strategy_name,\n",
    "                                                transform=tr_transforms, default_transform=tensor_transforms)\n",
    "    \n",
    "    db_train = ConcatDataset([db_train, db_train_al_labled, db_train_al_labled_da])\n",
    "\n",
    "    db_train_unlabled = BaseDataSets_HC18(base_dir=root_path, split=\"train\", num=labeled_slice, islabeled=False, \n",
    "                                            isAL=True, alNum=al_iter, stgrategy=strategy_name,\n",
    "                                            transform=None, default_transform=tensor_transforms)\n",
    "else:\n",
    "    db_train_unlabled = BaseDataSets_HC18(base_dir=root_path, split=\"train\", islabeled=False, \n",
    "                                                transform=None, default_transform=tensor_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_data in db_train_unlabled:\n",
    "    # print(i_data['idx'])\n",
    "    # print(i_data['name'])\n",
    "    # print(i_data['image'].shape)\n",
    "    # print(i_data['label'].shape)\n",
    "    test = np.unique(i_data['label'])\n",
    "    if len(test)>1:\n",
    "        print(test)\n",
    "        print(i_data['name'])\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41feec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_data in db_train:\n",
    "    # print(i_data['idx'])\n",
    "    # print(i_data['name'])\n",
    "    # print(i_data['image'].shape)\n",
    "    # print(i_data['label'].shape)\n",
    "    test = np.unique(i_data['label'])\n",
    "    if len(test)==1:\n",
    "        print(test)\n",
    "        print(i_data['name'])\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f728fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'total lenght of train data: {len(db_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0089b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'total lenght of train data: {len(db_train_unlabled)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_data in db_train:\n",
    "    # print(i_data['idx'])\n",
    "    print(i_data['name'])\n",
    "    print(i_data['image'].shape)\n",
    "    print(i_data['label'].shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d04072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a89f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
